{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Exploratory Data Analysis\n",
    "## Data Breach Patterns and Business Insights\n",
    "\n",
    "**Author:** T. Spivey  \n",
    "**Course:** BUS 761  \n",
    "**Assignment:** 5 - Exploratory Data Analysis Module  \n",
    "**Date:** October 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook demonstrates a comprehensive exploratory data analysis of 35,378 data breach incidents reported in the United States from 2003-2025. Using our newly developed **modular EDA package**, we uncover critical patterns in breach frequency, severity, and industry vulnerabilities.\n",
    "\n",
    "### Key Findings:\n",
    "1. **Industry-Specific Vulnerabilities**: Healthcare experiences 43% more disclosure breaches than expected\n",
    "2. **Financial Sector Risk**: Physical breaches are 169% higher than expected in financial services\n",
    "3. **Retail Targeting**: Payment card breaches in retail are 400% above statistical expectation\n",
    "4. **Impact Relationships**: Non-linear relationship between total and resident impact (Spearman ρ=0.52 vs Pearson r=0.32)\n",
    "5. **Temporal Trends**: Breach frequency and severity show distinct time-based patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "First, we'll import our modular EDA package and load the data from our SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom EDA package\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "from eda_package import BreachAnalyzer, BreachVisualizer, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "print(\"✓ Packages imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader('databreach.db')\n",
    "\n",
    "# Load main breach dataset\n",
    "df_breach = loader.load_breach_data()\n",
    "\n",
    "print(f\"Loaded {len(df_breach):,} breach records\")\n",
    "print(f\"Columns: {df_breach.shape[1]}\")\n",
    "print(f\"\\nData Range: {df_breach['breach_date'].min()} to {df_breach['breach_date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display database summary\n",
    "table_info = loader.get_table_info()\n",
    "print(\"\\nDatabase Tables:\")\n",
    "print(\"=\"*60)\n",
    "for table, count in table_info.items():\n",
    "    print(f\"{table:40s}: {count:>10,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview and Quality Assessment\n",
    "\n",
    "Let's examine the structure and quality of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few records\n",
    "print(\"Sample Records:\")\n",
    "df_breach.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment\n",
    "print(\"\\nData Quality Report\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Records: {len(df_breach):,}\")\n",
    "print(f\"\\nMissing Values by Column:\")\n",
    "missing = df_breach.isnull().sum()\n",
    "missing_pct = (missing / len(df_breach) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing Count': missing, 'Percentage': missing_pct})\n",
    "print(missing_df[missing_df['Missing Count'] > 0].sort_values('Percentage', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variable distributions\n",
    "print(\"\\nOrganization Type Distribution:\")\n",
    "print(df_breach['organization_type'].value_counts())\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nBreach Type Distribution:\")\n",
    "print(df_breach['breach_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistical Analysis\n",
    "\n",
    "Now we'll use our `BreachAnalyzer` class to conduct comprehensive statistical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = BreachAnalyzer(df_breach, alpha=0.05)\n",
    "print(f\"Analyzer initialized: {analyzer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Descriptive Statistics\n",
    "\n",
    "First, let's examine the central tendencies and distributions of key numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall descriptive statistics\n",
    "desc_stats_overall = analyzer.descriptive_statistics()\n",
    "print(\"\\nOverall Descriptive Statistics:\")\n",
    "print(\"=\"*80)\n",
    "desc_stats_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics by organization type\n",
    "desc_stats_by_org = analyzer.descriptive_statistics(group_by='organization_type')\n",
    "print(\"\\nDescriptive Statistics by Organization Type:\")\n",
    "print(\"=\"*80)\n",
    "desc_stats_by_org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Insight:** The data shows significant skewness (positive skewness values), indicating that most breaches are relatively small, but a few massive breaches drive up the mean. The median provides a better measure of \"typical\" breach size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Correlation Analysis\n",
    "\n",
    "Examine the relationship between total individuals affected and state residents affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "corr_results = analyzer.correlation_analysis()\n",
    "\n",
    "print(\"\\nCorrelation Analysis Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Variables: {corr_results['variable_1']} vs {corr_results['variable_2']}\")\n",
    "print(f\"Sample Size: {corr_results['sample_size']:,} valid pairs\\n\")\n",
    "\n",
    "print(f\"Pearson Correlation (Linear):\")\n",
    "print(f\"  r = {corr_results['pearson_r']:.4f}\")\n",
    "print(f\"  p-value = {corr_results['pearson_p']:.6f}\")\n",
    "print(f\"  Significant: {corr_results['pearson_significant']}\\n\")\n",
    "\n",
    "print(f\"Spearman Correlation (Monotonic):\")\n",
    "print(f\"  ρ = {corr_results['spearman_rho']:.4f}\")\n",
    "print(f\"  p-value = {corr_results['spearman_p']:.6f}\")\n",
    "print(f\"  Significant: {corr_results['spearman_significant']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Finding:** The difference between Pearson (r=0.32) and Spearman (ρ=0.52) suggests:\n",
    "- Strong monotonic relationship (rank-order)\n",
    "- Non-linear pattern in actual values\n",
    "- Presence of outliers affecting linear correlation\n",
    "- Typical in breach data where mega-breaches distort linear measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Chi-Squared Test: Industry vs Breach Type\n",
    "\n",
    "Test whether organization type and breach type are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-squared test\n",
    "chi_results = analyzer.chi_squared_test('organization_type', 'breach_type')\n",
    "\n",
    "print(\"\\nChi-Squared Test Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Null Hypothesis: {chi_results['variable_1']} and {chi_results['variable_2']} are independent\")\n",
    "print(f\"\\nχ² Statistic: {chi_results['chi2_statistic']:.2f}\")\n",
    "print(f\"p-value: {chi_results['p_value']:.8f}\")\n",
    "print(f\"Degrees of Freedom: {chi_results['degrees_of_freedom']}\")\n",
    "print(f\"Sample Size: {chi_results['sample_size']:,}\")\n",
    "print(f\"\\nConclusion: {'REJECT' if chi_results['significant'] else 'FAIL TO REJECT'} null hypothesis\")\n",
    "print(f\"Interpretation: {'Strong evidence of' if chi_results['significant'] else 'No significant'} relationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display observed frequencies\n",
    "print(\"\\nObserved Frequencies (Contingency Table):\")\n",
    "chi_results['observed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate deviations from expected\n",
    "deviation = chi_results['observed'] - chi_results['expected']\n",
    "deviation_pct = (deviation / chi_results['expected'] * 100).round(1)\n",
    "\n",
    "print(\"\\nDeviation from Expected (Percentage):\")\n",
    "print(\"Positive = More breaches than expected, Negative = Fewer\")\n",
    "deviation_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Critical Business Insights:**\n",
    "\n",
    "The significant chi-squared result (p < 0.001) confirms that different industries face different breach threats:\n",
    "\n",
    "1. **Healthcare (MED)**: 43% more DISC (disclosure) breaches → Focus on access controls\n",
    "2. **Financial (BSF)**: 169% more PHYS (physical) breaches → Strengthen document security\n",
    "3. **Retail (BSR)**: 400% more CARD breaches → Enhanced POS security critical\n",
    "4. **Business/Other (BSO)**: 15% more HACK attacks → Cyber defense priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 ANOVA: Breach Impact Across Industries\n",
    "\n",
    "Test whether breach severity differs significantly across organization types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA test\n",
    "anova_results = analyzer.anova_test('organization_type', 'total_affected')\n",
    "\n",
    "print(\"\\nANOVA Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Question: Does breach impact vary across organization types?\")\n",
    "print(f\"\\nF-Statistic: {anova_results['f_statistic']:.4f}\")\n",
    "print(f\"p-value: {anova_results['p_value']:.6f}\")\n",
    "print(f\"Number of Groups: {anova_results['n_groups']}\")\n",
    "print(f\"\\nConclusion: {'YES' if anova_results['significant'] else 'NO'} - \")\n",
    "print(f\"Breach impact {'DOES' if anova_results['significant'] else 'DOES NOT'} vary significantly by industry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display group statistics\n",
    "print(\"\\nGroup Statistics:\")\n",
    "anova_results['group_statistics'].sort_values('mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Linear Regression: Predicting Resident Impact\n",
    "\n",
    "Build a simple linear model to predict resident impact from total individuals affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression\n",
    "reg_results = analyzer.simple_linear_regression()\n",
    "\n",
    "print(\"\\nSimple Linear Regression Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: {reg_results['y_variable']} = {reg_results['slope']:.6f} * {reg_results['X_variable']} + {reg_results['intercept']:.2f}\")\n",
    "print(f\"\\nR² (Variance Explained): {reg_results['r_squared']:.4f}\")\n",
    "print(f\"Sample Size: {reg_results['sample_size']:,}\")\n",
    "print(f\"\\nInterpretation: {reg_results['r_squared']*100:.1f}% of variance in resident impact\")\n",
    "print(f\"                is explained by total individuals affected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Interpretation:**\n",
    "- Slope ≈ 0.0027: For every 1,000 total individuals affected, ~2.7 additional residents are affected\n",
    "- Low R² (0.099): Simple linear model explains only 10% of variance\n",
    "- Suggests: Need more complex model or additional predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Time Series Analysis\n",
    "\n",
    "Analyze breach trends over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series by year\n",
    "time_series = analyzer.time_series_analysis(freq='Y')\n",
    "\n",
    "print(\"\\nTime Series Analysis (Yearly):\")\n",
    "print(\"=\"*80)\n",
    "time_series.tail(10)  # Show last 10 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Logistic Regression: Predicting Severe Breaches\n",
    "\n",
    "Classify breaches as severe (>10,000 affected) or non-severe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "logit_results = analyzer.logistic_regression_severity(threshold=10000)\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Classification Threshold: {logit_results['threshold']:,} individuals\")\n",
    "print(f\"Model Accuracy: {logit_results['accuracy']:.2%}\")\n",
    "print(f\"\\nSevere Breaches: {logit_results['severe_count']:,}\")\n",
    "print(f\"Non-Severe Breaches: {logit_results['non_severe_count']:,}\")\n",
    "print(f\"\\nTop Coefficients (Highest Risk Factors):\")\n",
    "\n",
    "coef_df = pd.DataFrame.from_dict(logit_results['coefficients'], \n",
    "                                 orient='index', columns=['Coefficient'])\n",
    "coef_df.sort_values('Coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Visualization\n",
    "\n",
    "Now we'll use our `BreachVisualizer` class to create publication-quality visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "viz = BreachVisualizer(df_breach, output_dir='output/visualizations')\n",
    "print(f\"Visualizer initialized: {viz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive dashboard\n",
    "# Load necessary data for visualizations\n",
    "chi_observed = loader.load_statistical_results('chi_squared_observed')\n",
    "time_series_data = loader.load_statistical_results('time_series_yearly')\n",
    "\n",
    "# Prepare descriptive stats for visualization\n",
    "desc_for_viz = desc_stats_by_org.reset_index()\n",
    "desc_for_viz.columns = ['organization_type'] + desc_for_viz.columns[1:].tolist()\n",
    "\n",
    "# Create all visualizations\n",
    "viz.create_comprehensive_dashboard(\n",
    "    chi_observed=chi_observed,\n",
    "    desc_stats=desc_for_viz,\n",
    "    time_series=time_series_data,\n",
    "    correlation_stats=corr_results,\n",
    "    regression_results=reg_results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Business Insights Summary\n",
    "\n",
    "Let's generate actionable business insights from our analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get business insights\n",
    "insights = analyzer.get_business_insights()\n",
    "\n",
    "print(\"\\nBUSINESS INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "for category, insight in insights.items():\n",
    "    print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
    "    print(f\"  {insight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Strategic Recommendations\n",
    "\n",
    "Based on our comprehensive analysis, here are the key strategic recommendations:\n",
    "\n",
    "### For Healthcare Organizations (MED):\n",
    "- **Priority:** Disclosure prevention\n",
    "- **Action:** Implement stricter access controls and data handling procedures\n",
    "- **Rationale:** 43% more disclosure breaches than expected\n",
    "\n",
    "### For Financial Services (BSF):\n",
    "- **Priority:** Physical document security\n",
    "- **Action:** Enhanced document destruction protocols, secure storage\n",
    "- **Rationale:** 169% more physical breaches than expected\n",
    "\n",
    "### For Retail (BSR):\n",
    "- **Priority:** Payment card security\n",
    "- **Action:** POS system hardening, EMV compliance, fraud detection\n",
    "- **Rationale:** 400% more card breaches than expected\n",
    "\n",
    "### For All Organizations:\n",
    "- **Trend Monitoring:** Breach frequency and severity evolving over time\n",
    "- **Impact Planning:** Most breaches are small, but extreme outliers drive total impact\n",
    "- **Resource Allocation:** Industry-specific security investments provide better ROI\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "This exploratory data analysis has revealed significant patterns in data breach vulnerabilities across industries. Our modular EDA package enables:\n",
    "\n",
    "1. **Reusable Analysis:** Object-oriented design allows easy replication with new data\n",
    "2. **Statistical Rigor:** Multiple hypothesis tests confirm significant relationships\n",
    "3. **Business Focus:** Insights directly inform security investment decisions\n",
    "4. **Visualization Quality:** Publication-ready charts for stakeholder communication\n",
    "\n",
    "### Next Steps:\n",
    "- Develop predictive models (Assignment 6)\n",
    "- Create interactive dashboard (Assignment 7)\n",
    "- Monitor trends with updated data\n",
    "- Industry-specific deep dives\n",
    "\n",
    "---\n",
    "\n",
    "**Contact:** T. Spivey | BUS 761 | October 2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
